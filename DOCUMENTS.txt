PROJECT===============================================================

This project is to use a pipeline to generate photometric pixel data from SDSS images
and then apply MLZ machine learning onto the pixel data to precict redshifts
at the pixel scale. 

PIPELINE===============================================================

Instructions on the pipeline can be found in the README file on github reop.
The REAME file has instructions on the pipeline operations and required
softwares/python modules.
The test data generation and the machine learning parts are deleted.
The pipeline is to generate pixel data only.

Brief guide:

The pipeline requires
1) Montage
2) montge_wrapper
3) Sextractor (fftw and atlas)
4) Astropy
5) mpi4py (optional, for parallel computing)

Some important parameters in the config file are
1) IMAGE_PHOTOZ_PATH                -> where your working directory is
2) USE_MPI                          -> whether or not to enable parallel computing 
3) N_PROCESSORS                     -> number of processors to use
4) TRAINING_CATALOG                 -> name of the Casjobs file (more on Casjobs file later)
5) REGENERATE_TRAINING_CATOLOG      -> must be yes; otherwise no data generated
6) LOCAL_IMAGES                     -> whether or not to download the images from sdss database
7) USE_GALAXY/STAR/QUASAR/BACKROUND -> whether to generate pixel data for corresponding class
8) INTERMEDIATE_TRAINING_FILES      -> where to store registerd images
9) TRAINING_IMAGES_DIR              -> where to put original images 
10)TRAINING_CLASSIFIED_DATA_DIR     -> where to store pixel data
The rest are well explained. IGNORE everything related to machine learning
since that function has been disabled.
Some exmaples can be found on bigdog (see the path below).

Casjobs files are from the SDSS Casjobs. The pipeline requires the columns in
the Casjobs file to be in certain form. The query to generate such Casjobs
file cab be found in the "catolog_gen" folder in the pipeline package.
Only the CLEAN DATA in the sdss spectrum data are used.

Note that the number of background pixel can be adjusted in the 
generate_training/generate_training.py file in the package.

Short intro to how the pipeline works:
1) image registration
    The pipeline aligns five images of the five bands (ugriz) as well as the
    error images using Montage. This is to make sure the every pixel 
    are consistent in position in all five images (of the same run-camcol-field)
2) masking
    The pipeline then use Sextractor to mask out the dim pixels, leaving the
    bright pixels that are possible to be object pixels.
3) object identification
    The pipeline draws info from Casjobs file and examine these bright pixels.
    If the center position of an object predicted by Sextractor is consistent
    with the an object position in Casjobs, the pixels (within a scope) will
    be identified as the pixels belonging to that object. The Sextrator is to
    find out the pixel boudaries of objects.
4) data output
    Now all the pixels are catagorized correctly and their data are drawn from
    image and Casjobs. 

DATA=====================================================================

All the data are on bigdog-data in /data/large/imagepz/the-data/
There is also a REAME file that explain the data structures and names.
These data do not have pixel x and y.
There are 52GB of these old data currently on bigdog-data.
There are also some 1-squared-degree old testing pixel data.
The testing data have all the pixel data from very image.

The new data that have pixel x and y can be generated by the present pipeline.
Some are in the /data/large/imagepz/pipeline/photo-z-pixel# (# means number)
The new data from present pipeline is still scarce.
No new testing pixel data yet.
The present pipeline also stores registered images.

Note that some data files are empty. The reason is still unknown.

In the github repo there is a code to convert the generated data into hdf5
format. Instructions are in the code.

Structure of the output data:
Under the main folder "the-data" each folder is has the data generated from the same run of the pipeline. 
The number that follows "sqd" stands for the number of squared degrees the data cover.
In each of such folder there are four subfolder for different class of
objects: galaxy, star, quasar and background.
Expect for background, each file in the class folder contains pixel data for
one single object.
As for background folder, each file contains the pixel data from one image. 

Data columns:
u,g,r,i,z,zs,ezs,class,ra,dec,x,y,centerX,centerY,eu,eg,er,ei,ez
The u,g,r,i,z,ra,dec,x,y,eu,eg,er,ei,ez are from pixels, while the rest are from objects.
The redshift (zs) is not determined for background pixels. 
This is a tricky issue that has yet to be solved.

TRAINING===================================================================

...
